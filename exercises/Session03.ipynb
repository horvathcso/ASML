{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "618bcfd4",
      "metadata": {
        "tags": [],
        "id": "618bcfd4"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import scipy.io as spio"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb240ca9",
      "metadata": {
        "tags": [],
        "id": "eb240ca9"
      },
      "source": [
        "# Bayesian linear regression\n",
        "\n",
        "In this exercise session we consider the supervised regression problem of finding a function $f(x)$ that describes the relationship between a scalar input $x$ and a scalar output $y$:\n",
        "\n",
        "$$\n",
        "y = f(x) + \\epsilon, \\qquad \\epsilon \\sim \\mathcal{N}(0, \\beta^{-1}).\n",
        "$$\n",
        "\n",
        "We model this with a Bayesian linear regression model\n",
        "\n",
        "$$\n",
        "f(x) = \\boldsymbol{\\phi}(x)^{\\mathsf{T}} \\mathbf{w}, \\qquad \\mathbf{w} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_0, \\mathbf{S}_0),\n",
        "$$\n",
        "\n",
        "where $\\boldsymbol{\\phi}(x)$ is a vector of the input features.\n",
        "Note that we used the notation $\\mathbf{x}$ for the input features in the lecture.\n",
        "We changed this notation to $\\boldsymbol{\\phi}(x)$ here in order to not mix it up with the scalar input $x$.\n",
        "\n",
        "The Bayesian linear regression model is then given by\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "p(\\mathbf{y} \\,|\\, \\mathbf{w}) &= \\mathcal{N}(\\mathbf{y}; \\boldsymbol{\\Phi}\\mathbf{w}, \\beta^{-1}\\mathbf{I}_N) \\qquad && \\text{(likelihood)}, \\\\\n",
        "p(\\mathbf{w}) &= \\mathcal{N}(\\mathbf{w}; \\mathbf{m}_0, \\mathbf{S}_0) \\qquad && \\text{(prior)},\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where\n",
        "\n",
        "$$\n",
        "\\boldsymbol{\\Phi} = \\begin{bmatrix} \\boldsymbol{\\phi}(x_1)^{\\mathsf{T}} \\\\ \\vdots \\\\ \\boldsymbol{\\phi}(x_N)^{\\mathsf{T}} \\end{bmatrix}\n",
        "\\qquad \\text{and} \\qquad\n",
        "\\mathbf{y} = \\begin{bmatrix} y_1 \\\\ \\vdots \\\\ y_N \\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Given a set of training data of inputs and outputs $\\mathcal{D} = \\{(x_i, y_i)\\}_{i=1}^N$, we are interested in finding the posterior of the weights $p(\\mathbf{w} \\,|\\, \\mathbf{y})$ and also the predictive distribution $p(f(x_{\\star}) \\,|\\, \\mathbf{y})$ of unseen input $x_{\\star}$.\n",
        "For further information about the Bayesian linear regression model see Lecture 3 and/or Christopher Bishop's book [\"Pattern recognition and machine learning\"](https://www.microsoft.com/en-us/research/publication/pattern-recognition-machine-learning/)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8bc748e",
      "metadata": {
        "tags": [],
        "id": "c8bc748e"
      },
      "source": [
        "\n",
        "## Exercise 3.1: Understanding the code\n",
        "\n",
        "Download the files <a href=\"https://uni-tuebingen.de/fileadmin/Uni_Tuebingen/Fakultaeten/MatNat/Fachbereiche/Informatik/Lehrstuehle/MethMaschLern/Probabilistic_ML/Notebook_Vorlesung_7___9/lindata.mat\" download=\"lindata.mat\">`lindata.mat`</a> and <a href=\"https://uni-tuebingen.de/fileadmin/Uni_Tuebingen/Fakultaeten/MatNat/Fachbereiche/Informatik/Lehrstuehle/MethMaschLern/Probabilistic_ML/Notebook_Vorlesung_7___9/nlindata.mat\" download=\"nlindata.mat\">`nlindata.mat`</a> and save them to the folder of this notebook.\n",
        "These datasets are borrowed from Philipp Hennig's course [\"Probabilistic machine learning\"](https://uni-tuebingen.de/en/180804), given at the University of TÃ¼bingen.\n",
        "\n",
        "The following code cell loads inputs, outputs, and precision parameter from `lindata.mat` and plots the feature vector\n",
        "\n",
        "$$\n",
        "\\boldsymbol{\\phi}(x)^{\\mathsf{T}} = [1, x].\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f6b1173",
      "metadata": {
        "tags": [],
        "id": "0f6b1173"
      },
      "outputs": [],
      "source": [
        "# Load data from disk\n",
        "# File should be in the same folder as the Jupyter notebook,\n",
        "# otherwise you have to adjust the path\n",
        "data = spio.loadmat(\"lindata.mat\")\n",
        "x = data[\"X\"].flatten() # inputs\n",
        "y = data[\"Y\"].flatten() # outputs\n",
        "beta = float(data[\"sigma\"])**(-2) # measurement noise precision\n",
        "N = x.size\n",
        "\n",
        "# Define the feature vector\n",
        "def Phi(a):  # Phi(a) = [1, a]\n",
        "    return np.power(np.reshape(a, (-1, 1)), range(2))\n",
        "\n",
        "# Plot the features\n",
        "plt.plot(x, Phi(x), '-o')\n",
        "plt.title('features')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94fd062e",
      "metadata": {
        "tags": [],
        "id": "94fd062e"
      },
      "source": [
        "We then compute the posterior distribution of the weights $\\mathbf{w}$ of a Bayesian linear regression model using these features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b51efc98",
      "metadata": {
        "tags": [],
        "id": "b51efc98"
      },
      "outputs": [],
      "source": [
        "# Define the prior on the weights\n",
        "# p(w) = N(w; m0, S0)\n",
        "D = Phi(0).size  # number of features\n",
        "m0 = np.zeros(D)\n",
        "S0 = 10*np.eye(D) / D\n",
        "\n",
        "# Compute the posterior distribution of the Bayesian linear regression model\n",
        "# p(w | y) = N(w; mN, SN)\n",
        "SN = np.linalg.inv(np.linalg.inv(S0) + beta * Phi(x).T @ Phi(x))\n",
        "mN = SN @ (np.linalg.inv(S0) @ m0 + beta * Phi(x).T @ y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49a08758",
      "metadata": {
        "tags": [],
        "id": "49a08758"
      },
      "source": [
        "We visualize the posterior distribution by plotting the functions $f$ corresponding to different samples of $\\mathbf{w}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f9ebde2",
      "metadata": {
        "tags": [],
        "id": "6f9ebde2"
      },
      "outputs": [],
      "source": [
        "# Generate grid of new inputs x* for plotting\n",
        "n = 100  # number of grid-points\n",
        "xs = np.linspace(-8, 8, n)\n",
        "\n",
        "# Visualize the posterior p(w | y) = N(w; mN, SN)\n",
        "# For samples of w, f(x) = phi(x)^T w is evaluated at inputs xs\n",
        "# Draw samples of w from the posterior\n",
        "samples = 5\n",
        "seed = 100\n",
        "ws = stats.multivariate_normal(mean=mN, cov=SN, allow_singular=True).rvs(samples, random_state=seed)\n",
        "\n",
        "# Compute corresponding values f(x*)\n",
        "fs = Phi(xs) @ ws.T\n",
        "\n",
        "# Plot the samples\n",
        "plt.plot(xs, fs, 'gray') # samples\n",
        "plt.scatter(x, y, zorder=3)\n",
        "plt.title('posterior - samples')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2415e984",
      "metadata": {
        "tags": [],
        "id": "2415e984"
      },
      "source": [
        "Next we plot samples from and credibility regions of the predictive distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0ec3962",
      "metadata": {
        "tags": [],
        "id": "b0ec3962"
      },
      "outputs": [],
      "source": [
        "# Compute the predictive distribution of the outputs y*\n",
        "# p(y* | y) = N(y*; m*, S*)\n",
        "mstar = Phi(xs) @ mN\n",
        "Sstar = Phi(xs) @ SN @ Phi(xs).T + beta**(-1) * np.eye(n)\n",
        "\n",
        "# Extract standard deviation of predictive distribution\n",
        "stdpred= np.sqrt(np.diag(Sstar))\n",
        "\n",
        "# Plot credibility regions\n",
        "plt.plot(xs, mstar, 'black') # predictive mean\n",
        "plt.fill_between(xs, mstar + 3*stdpred, mstar - 3*stdpred, color='lightgray')\n",
        "plt.fill_between(xs, mstar + 2*stdpred, mstar - 2*stdpred, color='darkgray')\n",
        "plt.fill_between(xs, mstar + 1*stdpred, mstar - 1*stdpred, color='gray')\n",
        "plt.scatter(x, y, zorder=3)\n",
        "plt.title('predictive distribution')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0013d607",
      "metadata": {
        "tags": [],
        "id": "0013d607"
      },
      "source": [
        "### (a)\n",
        "\n",
        "Go through the code and make sure that you can map the code to the model and regression method explained in Lecture 3.\n",
        "Also run the code.\n",
        "Make sure you understand the figures."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ec0520b",
      "metadata": {
        "tags": [],
        "id": "1ec0520b"
      },
      "source": [
        "### (b)\n",
        "\n",
        "Reduce the training data to only the first 5 data points in the training data.\n",
        "What impact does this have on the predictive distribution?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f58d784",
      "metadata": {
        "tags": [],
        "id": "7f58d784"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7862dce0",
      "metadata": {
        "tags": [],
        "id": "7862dce0"
      },
      "source": [
        "## Exercise 3.2: Feature vectors\n",
        "\n",
        "### (a)\n",
        "\n",
        "Load `nlindata.mat` instead of `lindata.mat` and run the code for this data.\n",
        "Use all data, not only the first five data points as in Exercise 3.1 (b).\n",
        "Do you think the model performs well on this data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17323022",
      "metadata": {
        "tags": [],
        "id": "17323022"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7cb5f804",
      "metadata": {
        "tags": [],
        "id": "7cb5f804"
      },
      "source": [
        "### (b)\n",
        "\n",
        "In order to improve the performance, consider instead a feature vector with an additional quadratic term\n",
        "\n",
        "$$\n",
        "\\boldsymbol{\\phi}(x)^{\\mathsf{T}} = [1, x, x^2].\n",
        "$$\n",
        "\n",
        "Change the code accordingly and run it.\n",
        "\n",
        "*Hint:* Only a very minor modification in the code is required to accommodate for this change."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "741dc020",
      "metadata": {
        "tags": [],
        "id": "741dc020"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "971f6a00",
      "metadata": {
        "tags": [],
        "id": "971f6a00"
      },
      "source": [
        "### (c)\n",
        "\n",
        "Use step functions\n",
        "\n",
        "$$\n",
        "h(x) = \\begin{cases}\n",
        "1, \\qquad x \\geq 0,\\\\\n",
        "0, \\qquad x < 0,\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "as features and change the code accordingly.\n",
        "Place in total 9 of these features with two steps apart between $x = -8$ and $x = 8$.\n",
        "The feature vector is then\n",
        "\n",
        "$$\n",
        "\\boldsymbol{\\phi}(x)^{\\mathsf{T}} = [h(x-8), h(x - 6), \\ldots, h(x + 8)].\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a131e515",
      "metadata": {
        "tags": [],
        "id": "a131e515"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "3f78e53b",
      "metadata": {
        "tags": [],
        "id": "3f78e53b"
      },
      "source": [
        "### (d)\n",
        "\n",
        "Can you come up with any other features that improve performance even further?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "989217ea",
      "metadata": {
        "tags": [],
        "id": "989217ea"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "29bbcaea",
      "metadata": {
        "tags": [],
        "id": "29bbcaea"
      },
      "source": [
        "## Exercise 3.3: Marginal likelihood\n",
        "\n",
        "To get a quantitative measure of the performance of the proposed feature vectors, we want to compare them by computing the marginal likelihood $p(\\mathbf{y})$ for each of the models.\n",
        "Refer to Exercise 2.12(a) for the expression of the marginal likelihood of the Bayesian linear regression model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb469eb1",
      "metadata": {
        "tags": [],
        "id": "cb469eb1"
      },
      "source": [
        "### (a)\n",
        "\n",
        "Extend the code to also compute the logarithm of the marginal likelihood.\n",
        "Which one of the three feature vectors in Exercise 3.2 gives the largest log marginal likelihood on the data `nlindata.mat`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1740bcd3",
      "metadata": {
        "tags": [],
        "id": "1740bcd3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7b657800",
      "metadata": {
        "tags": [],
        "id": "7b657800"
      },
      "source": [
        "### (b)\n",
        "\n",
        "Perform the same comparison on the data `lindata.mat`.\n",
        "What are your conclusions?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "725372bc",
      "metadata": {
        "tags": [],
        "id": "725372bc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "cfd64388",
      "metadata": {
        "tags": [],
        "id": "cfd64388"
      },
      "source": [
        "### (c)\n",
        "\n",
        "Can you come up with any other feature vectors and/or values for prior/likelihood precisions that give an even larger log marginal likelihood?"
      ]
    }
  ],
  "metadata": {
    "@webio": {
      "lastCommId": null,
      "lastKernelId": null
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "e0466e4bbc1f6f77653f92f7ee99fe375173484495b8b5339e7493ccb72bc580"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}